{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e16b4208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem import *\n",
    "from nltk import word_tokenize\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4792d4a4",
   "metadata": {},
   "source": [
    "## Выгрузка данных из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae07ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['comp.graphics', 'comp.os.ms-windows.misc', 'rec.autos']\n",
    "remove = ['headers', 'footers', 'quotes']\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories=categories, remove=remove)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42, categories=categories, remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "924c81ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = pd.DataFrame(twenty_train, columns=['data', 'target']).replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True)\n",
    "twenty_test = pd.DataFrame(twenty_test, columns=['data', 'target']).replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3233496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(data):\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    nltk_tokens = word_tokenize(data)\n",
    "    line = ''\n",
    "    for word in nltk_tokens:\n",
    "        line += ' ' + porter_stemmer.stem(word)\n",
    "    return line\n",
    "\n",
    "twenty_train.insert(loc=1, column='data_stemmed', value=twenty_train['data'].apply(lambda text: stemming(text)))\n",
    "twenty_test.insert(loc=1, column='data_stemmed', value=twenty_test['data'].apply(lambda text: stemming(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a78c74f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings \n",
    "from sklearn.exceptions import FitFailedWarning, ConvergenceWarning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "32fe78d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuvik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "420 fits failed out of a total of 840.\n",
      "The score on these train-test partitions for these parameters will be set to 0.0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "420 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nuvik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nuvik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\nuvik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nuvik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 17.2 s\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "    'RandomForestClassifier': {\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__criterion': ['gini','entropy','log_loss'],\n",
    "        'clf__max_depth': [3,5,10,None]\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__penalty': ['l1','l2'], \n",
    "        'clf__C': [0.001,0.01,0.1,1,10,100,1000]\n",
    "    },\n",
    "    'KNeighborsClassifier': {\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__n_neighbors': (1, 3, 5, 10),\n",
    "        'clf__p': (1, 2)\n",
    "    }\n",
    "}\n",
    "\n",
    "gs = {}\n",
    "for clf, param in parameters.items():\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', eval(clf)())\n",
    "    ])\n",
    "    gs[clf] = GridSearchCV(text_clf, param, n_jobs=-1, error_score=0.0)\n",
    "    gs[clf].fit(X = twenty_train['data'], y = twenty_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ca430db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "          comp.graphics       0.83      0.74      0.78       389\n",
      "comp.os.ms-windows.misc       0.83      0.76      0.79       394\n",
      "              rec.autos       0.79      0.94      0.86       396\n",
      "\n",
      "               accuracy                           0.81      1179\n",
      "              macro avg       0.82      0.81      0.81      1179\n",
      "           weighted avg       0.82      0.81      0.81      1179\n",
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "          comp.graphics       0.84      0.85      0.84       389\n",
      "comp.os.ms-windows.misc       0.90      0.74      0.81       394\n",
      "              rec.autos       0.84      0.97      0.90       396\n",
      "\n",
      "               accuracy                           0.85      1179\n",
      "              macro avg       0.86      0.85      0.85      1179\n",
      "           weighted avg       0.86      0.85      0.85      1179\n",
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "          comp.graphics       0.59      0.35      0.44       389\n",
      "comp.os.ms-windows.misc       0.61      0.37      0.46       394\n",
      "              rec.autos       0.46      0.82      0.59       396\n",
      "\n",
      "               accuracy                           0.51      1179\n",
      "              macro avg       0.55      0.51      0.49      1179\n",
      "           weighted avg       0.55      0.51      0.49      1179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf, param in parameters.items():\n",
    "    predicted = gs[clf].predict(twenty_test['data'])\n",
    "    print(metrics.classification_report(twenty_test.target, predicted, target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c2b3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = {}\n",
    "def highlight_max(x, color):\n",
    "\n",
    "    return np.where(x == np.nanmax(x.to_numpy()), f\"color: {color};\", None)\n",
    "\n",
    "total_style = pd.Series(\"font-weight: bold;\", index=[1])\n",
    "\n",
    "for clf, param in parameters.items():\n",
    "    predicted = gs[clf].predict(twenty_test['data'])\n",
    "    \n",
    "    pd.DataFrame(gs[clf].cv_results_).to_excel('all' + clf + '.xlsx')\n",
    "    pd.DataFrame(classification_report(predicted, twenty_test.target, output_dict=True)).to_excel('best' + clf + '.xlsx')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339715b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a77e2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
